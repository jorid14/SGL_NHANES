{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives**\n",
    "\n",
    "Provide an overview of some machine learning models, using the latest iteration of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Applied Data Filters**\n",
    "\n",
    "The dataframe included in this analysis contains the following modifications of the original data set:\n",
    "\n",
    "1. Meal level aggregation\n",
    "2. Meals that are only lunch or dinner\n",
    "3. Meals that have both seafood and meat, where there is ambiguity in the ratio, are dropped\n",
    "4. Meals that are more than 0 KCAL\n",
    "5. Meals of participants older than 18 years of age\n",
    "6. Meals that are consumed at home\n",
    "7. Meals that are non-vegeterian "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 1: Logistic Regression Model**\n",
    "\n",
    "**Model Evaluation**\n",
    "\n",
    "This section evaluated the performance of the logistic regression model over several model fittings. This is done to account for the random sampling of the model data. The performance is measured by a split of the data into training and test sets, using an 80% training and 20% test split. The prediction success rate of the model is used as the evaluation criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count  100.000000\n",
      "mean     0.668650\n",
      "std      0.033043\n",
      "min      0.580000\n",
      "25%      0.640000\n",
      "50%      0.665000\n",
      "75%      0.690000\n",
      "max      0.765000\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.691788\n",
      "std      0.016534\n",
      "min      0.643750\n",
      "25%      0.681250\n",
      "50%      0.691250\n",
      "75%      0.701563\n",
      "max      0.725000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def nhanes_full_log_reg(df, fped_vars, non_sfd_class_n, sfd_class_n, test_ratio):\n",
    "    \n",
    "    #Sample the seafood and non-seafood classes, create model input df\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=non_sfd_class_n)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=sfd_class_n)\n",
    "    df_mdl = pd.concat([df_non_sfd, df_sfd])\n",
    "    #Add the classification target variable to the df input list\n",
    "    fped_vars.append('seafood_meal')\n",
    "    #Use variable combination selected by loop\n",
    "    df_mdl = df_mdl[fped_vars]\n",
    "    #Split the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_mdl.drop(['seafood_meal'], axis=1), df_mdl['seafood_meal'], test_size=test_ratio)\n",
    "    #Fit the logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    #Obtain predictions on test set and calculate success rate\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    y_pred_train = log_reg.predict(X_train)\n",
    "    n_correct = sum(y_pred == y_test)\n",
    "    pred_sr = [str(n_correct/len(y_pred))]\n",
    "    n_correct_train = sum(y_pred_train == y_train)\n",
    "    pred_sr_train = [str(n_correct_train/len(y_pred_train))]\n",
    "    #Calculate model execution time for combinatorial variable selection    \n",
    "    #non_cmb_time = time.time() - startTime  \n",
    "    #non_cmb_time_df = pd.DataFrame([non_cmb_time ])\n",
    "    #non_cmb_time_df = non_cmb_time_df.rename({0: 'Runtime(Seconds)'}, axis=1)\n",
    "    #Create a dataframe with variables used and their success rate    \n",
    "    pred_sr_df = pd.DataFrame(pred_sr)\n",
    "    pred_sr_df = pred_sr_df.rename({0: 'Success Rate'}, axis=1)\n",
    "    pred_sr_train_df = pd.DataFrame(pred_sr_train)\n",
    "    pred_sr_train_df = pred_sr_train_df.rename({0: 'Success Rate Train'}, axis=1)\n",
    "    fped_vars.remove('seafood_meal')\n",
    "    var_list_df = pd.DataFrame([fped_vars])\n",
    "    #model_result = pd.concat([var_list_df, pred_sr_df, non_cmb_time_df], axis=1)\n",
    "    model_result = pd.concat([var_list_df, pred_sr_df], axis=1)\n",
    "    return pred_sr, pred_sr_train\n",
    "\n",
    "#Level 5 has all components of level4, but breaks the total fruit into subcomponents\n",
    "food_cmp_level5 = ['F_CITMLB', 'F_OTHER', 'F_JUICE', \n",
    "                   'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', \n",
    "                   'V_STARCHY_OTHER', 'V_OTHER', 'V_LEGUMES', \n",
    "                   'G_WHOLE','G_REFINED', \n",
    "                   'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', \n",
    "                   'D_MILK', 'D_YOGURT', 'D_CHEESE', \n",
    "                   'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']  \n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "#df = df[df['meal_energy']=='Medium-Low']\n",
    "\n",
    "test_pred_sr_tot=[]\n",
    "train_pred_sr_tot=[]\n",
    "for i in range(100):\n",
    "    test_pred_sr, train_pred_sr = nhanes_full_log_reg(df = df,\n",
    "                                   fped_vars = food_cmp_level5, \n",
    "                                   non_sfd_class_n = 500, \n",
    "                                   sfd_class_n = 500, \n",
    "                                   test_ratio = 0.2, )\n",
    "    test_pred_sr_tot.append(test_pred_sr)\n",
    "    train_pred_sr_tot.append(train_pred_sr)\n",
    "\n",
    "\n",
    "test_pred_sr_tot = pd.DataFrame(test_pred_sr_tot)\n",
    "test_pred_sr_tot = test_pred_sr_tot.astype(float)\n",
    "train_pred_sr_tot = pd.DataFrame(train_pred_sr_tot)\n",
    "train_pred_sr_tot = train_pred_sr_tot.astype(float)\n",
    "print(test_pred_sr_tot.describe())\n",
    "print(train_pred_sr_tot.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above is showing the prediction success rate results of the model over 100 runs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Interpretation**\n",
    "\n",
    "This section performs a single fit of the logistic regression model and obtains the regression coefficients. Using the coefficients derived from the fitted model, the probability of a meal containing seafood or not can be obtained by the following equation:\n",
    "\n",
    "$$p(X) = \\frac{e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}{1 + e^{\\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p}}$$\n",
    "\n",
    "Where $$\\beta_0$$ is the intercept. When trying to interpret the impact of a single component, we can see that the probability depends on the initial values of the other components. Therefore, the only valuable information from the coefficient values themselves is the sign. If the sign is positive, then we know that increasing the value of the component will increase the probability while the inverse is true of a negative sign. \n",
    "\n",
    "Below is an example for the model interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression coefficients are: \n",
      " [[ 0.08222276  0.06002173  0.21907392  0.47690617 -0.70093408  0.04377328\n",
      "  -0.78568938  0.55252968  0.3767677  -0.07365238  0.03798739 -0.02285348\n",
      "   0.76637344  0.73451413 -0.3296796  -0.26648785  0.1880487   0.02029124\n",
      "  -1.19041458  0.04211146 -0.02265897 -0.03155641 -0.02966232]]\n",
      "\n",
      "\n",
      "The logistic regression intercept is: \n",
      " [0.06910692]\n"
     ]
    }
   ],
   "source": [
    "def nhanes_full_log_reg_params(df, fped_vars, non_sfd_class_n, sfd_class_n, test_ratio):\n",
    "    \n",
    "    #Sample the seafood and non-seafood classes, create model input df\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=non_sfd_class_n, random_state=1)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=sfd_class_n, random_state=1)\n",
    "    df_mdl = pd.concat([df_non_sfd, df_sfd])\n",
    "    #Add the classification target variable to the df input list\n",
    "    fped_vars.append('seafood_meal')\n",
    "    #Use variable combination selected by loop\n",
    "    df_mdl = df_mdl[fped_vars]\n",
    "    #Split the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_mdl.drop(['seafood_meal'], axis=1), df_mdl['seafood_meal'], test_size=test_ratio, random_state=1)\n",
    "    #Fit the logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    #Obtain predictions on test set and calculate success rate\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    n_correct = sum(y_pred == y_test)\n",
    "    pred_sr = [str(n_correct/len(y_pred))]\n",
    "    pred_sr_df = pd.DataFrame(pred_sr)\n",
    "    pred_sr_df = pred_sr_df.rename({0: 'Success Rate'}, axis=1)\n",
    "    fped_vars.remove('seafood_meal')\n",
    "    var_list_df = pd.DataFrame([fped_vars])\n",
    "    #model_result = pd.concat([var_list_df, pred_sr_df, non_cmb_time_df], axis=1)\n",
    "    model_result = pd.concat([var_list_df, pred_sr_df], axis=1)\n",
    "    return log_reg.coef_, log_reg.intercept_\n",
    "\n",
    "\n",
    "food_cmp_level5 = ['F_CITMLB', 'F_OTHER', 'F_JUICE', \n",
    "                   'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', \n",
    "                   'V_STARCHY_OTHER', 'V_OTHER', 'V_LEGUMES', \n",
    "                   'G_WHOLE','G_REFINED', \n",
    "                   'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', \n",
    "                   'D_MILK', 'D_YOGURT', 'D_CHEESE', \n",
    "                   'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']  \n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "\n",
    "log_reg_coefficients, log_reg_intercept = nhanes_full_log_reg_params(df = df,\n",
    "                                   fped_vars = food_cmp_level5, \n",
    "                                   non_sfd_class_n = 500, \n",
    "                                   sfd_class_n = 500, \n",
    "                                   test_ratio = 0.2)\n",
    "\n",
    "\n",
    "print(\"The logistic regression coefficients are: \\n\", log_reg_coefficients)\n",
    "print(\"\\n\")\n",
    "print(\"The logistic regression intercept is: \\n\", log_reg_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0             1             2             3             4   \\\n",
      "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
      "mean   8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "std    5.579081e-17  8.368621e-17  5.579081e-17  7.810713e-16  6.694897e-16   \n",
      "min    8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "25%    8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "50%    8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "75%    8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "max    8.222276e-02  6.002173e-02  2.190739e-01  4.769062e-01 -7.009341e-01   \n",
      "\n",
      "               5             6             7           8             9   ...  \\\n",
      "count  100.000000  1.000000e+02  1.000000e+02  100.000000  1.000000e+02  ...   \n",
      "mean     0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "std      0.000000  6.694897e-16  8.926529e-16    0.000000  9.763391e-17  ...   \n",
      "min      0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "25%      0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "50%      0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "75%      0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "max      0.043773 -7.856894e-01  5.525297e-01    0.376768 -7.365238e-02  ...   \n",
      "\n",
      "                 13            14            15            16            17  \\\n",
      "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02   \n",
      "mean   7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "std    1.115816e-16  3.347448e-16  6.136989e-16  2.231632e-16  2.092155e-17   \n",
      "min    7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "25%    7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "50%    7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "75%    7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "max    7.345141e-01 -3.296796e-01 -2.664879e-01  1.880487e-01  2.029124e-02   \n",
      "\n",
      "                 18            19            20            21            22  \n",
      "count  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  1.000000e+02  \n",
      "mean  -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "std    1.785306e-15  2.092155e-17  5.579081e-17  5.579081e-17  6.973851e-18  \n",
      "min   -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "25%   -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "50%   -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "75%   -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "max   -1.190415e+00  4.211146e-02 -2.265897e-02 -3.155641e-02 -2.966232e-02  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "def nhanes_full_log_reg_params(df, fped_vars, non_sfd_class_n, sfd_class_n, test_ratio):\n",
    "    \n",
    "    #Sample the seafood and non-seafood classes, create model input df\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=non_sfd_class_n, random_state=1)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=sfd_class_n, random_state=1)\n",
    "    df_mdl = pd.concat([df_non_sfd, df_sfd])\n",
    "    #Add the classification target variable to the df input list\n",
    "    fped_vars.append('seafood_meal')\n",
    "    #Use variable combination selected by loop\n",
    "    df_mdl = df_mdl[fped_vars]\n",
    "    #Split the training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_mdl.drop(['seafood_meal'], axis=1), df_mdl['seafood_meal'], test_size=test_ratio, random_state=1)\n",
    "    #Fit the logistic regression model\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    #Obtain predictions on test set and calculate success rate\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "    n_correct = sum(y_pred == y_test)\n",
    "    pred_sr = [str(n_correct/len(y_pred))]\n",
    "    pred_sr_df = pd.DataFrame(pred_sr)\n",
    "    pred_sr_df = pred_sr_df.rename({0: 'Success Rate'}, axis=1)\n",
    "    fped_vars.remove('seafood_meal')\n",
    "    var_list_df = pd.DataFrame([fped_vars])\n",
    "    #model_result = pd.concat([var_list_df, pred_sr_df, non_cmb_time_df], axis=1)\n",
    "    model_result = pd.concat([var_list_df, pred_sr_df], axis=1)\n",
    "    return log_reg.coef_, log_reg.intercept_\n",
    "\n",
    "\n",
    "food_cmp_level5 = ['F_CITMLB', 'F_OTHER', 'F_JUICE', \n",
    "                   'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', \n",
    "                   'V_STARCHY_OTHER', 'V_OTHER', 'V_LEGUMES', \n",
    "                   'G_WHOLE','G_REFINED', \n",
    "                   'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', \n",
    "                   'D_MILK', 'D_YOGURT', 'D_CHEESE', \n",
    "                   'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']  \n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "\n",
    "\n",
    "a = []\n",
    "for i in range(100):\n",
    "    log_reg_coefficients, log_reg_intercept = nhanes_full_log_reg_params(df = df,\n",
    "                                       fped_vars = food_cmp_level5, \n",
    "                                       non_sfd_class_n = 500, \n",
    "                                       sfd_class_n = 500, \n",
    "                                       test_ratio = 0.2)\n",
    "    a.append(log_reg_coefficients)\n",
    "    \n",
    "\n",
    "a = pd.DataFrame(np.concatenate(a))\n",
    "print(a.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectors printed above represent the coefficients from the fitted logistic regression model, using the level 5 FPED components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression variables are: \n",
      " ['F_CITMLB', 'F_OTHER', 'F_JUICE', 'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', 'V_STARCHY_OTHER', 'V_OTHER', 'V_LEGUMES', 'G_WHOLE', 'G_REFINED', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', 'D_MILK', 'D_YOGURT', 'D_CHEESE', 'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The logistic regression variables are: \\n\", food_cmp_level5)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, due to the high number of components/parameters that are used in the model, even the signs of the parameters are random in nature. This is because the model fit convergence can arrive at different solutions. The model fitting algorithms use a random point for initializing the algorithm. And with the model of this size, this will affect the parameter sign, depending on when the algorithm arrives at a solution. For example, running the model again will yield the following solution, where we can see that some of the parameter signs are different: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The logistic regression coefficients are: \n",
      " [[-0.06971927 -0.13028231  0.52887761  0.42064084 -0.55416455 -0.0284824\n",
      "  -0.49418688  0.57011787  0.51343868 -0.08268138  0.21338709  0.02828873\n",
      "   0.81689587  0.19440342 -0.22312681 -0.30616341  0.38247213  0.06824989\n",
      "  -1.05100914  0.0363042  -0.02564836 -0.03278337  0.0121854 ]]\n",
      "\n",
      "\n",
      "The logistic regression intercept is: \n",
      " [-0.08784222]\n"
     ]
    }
   ],
   "source": [
    "log_reg_coefficients, log_reg_intercept = nhanes_full_log_reg_params(df = df,\n",
    "                                   fped_vars = food_cmp_level5, \n",
    "                                   non_sfd_class_n = 500, \n",
    "                                   sfd_class_n = 500, \n",
    "                                   test_ratio = 0.2)\n",
    "\n",
    "\n",
    "print(\"The logistic regression coefficients are: \\n\", log_reg_coefficients)\n",
    "print(\"\\n\")\n",
    "print(\"The logistic regression intercept is: \\n\", log_reg_intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, it is not advisable to draw inferences from the parameter values of the model. This may also be due to the low performance of the model, i.e. the model is not very representative of the real world. This may lead the model to arrive at different solutions, especially for components that do not provide a clear contribution. Below is an example of how to interpret the model derived above. First, we can obtain a meal at random from the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F_CITMLB</th>\n",
       "      <th>F_OTHER</th>\n",
       "      <th>F_JUICE</th>\n",
       "      <th>V_DRKGR</th>\n",
       "      <th>V_REDOR_TOMATO</th>\n",
       "      <th>V_REDOR_OTHER</th>\n",
       "      <th>V_STARCHY_POTATO</th>\n",
       "      <th>V_STARCHY_OTHER</th>\n",
       "      <th>V_OTHER</th>\n",
       "      <th>V_LEGUMES</th>\n",
       "      <th>...</th>\n",
       "      <th>PF_SOY</th>\n",
       "      <th>PF_NUTSDS</th>\n",
       "      <th>PF_LEGUMES</th>\n",
       "      <th>D_MILK</th>\n",
       "      <th>D_YOGURT</th>\n",
       "      <th>D_CHEESE</th>\n",
       "      <th>OILS</th>\n",
       "      <th>SOLID_FATS</th>\n",
       "      <th>ADD_SUGARS</th>\n",
       "      <th>A_DRINKS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F_CITMLB  F_OTHER  F_JUICE  V_DRKGR  V_REDOR_TOMATO  V_REDOR_OTHER  \\\n",
       "4939       0.0      0.0      3.6     0.03             0.2            0.0   \n",
       "\n",
       "      V_STARCHY_POTATO  V_STARCHY_OTHER  V_OTHER  V_LEGUMES  ...  PF_SOY  \\\n",
       "4939               0.0              0.0     0.49        0.0  ...     0.0   \n",
       "\n",
       "      PF_NUTSDS  PF_LEGUMES  D_MILK  D_YOGURT  D_CHEESE  OILS  SOLID_FATS  \\\n",
       "4939        0.0         0.0     0.0       0.0       0.0  1.96        0.09   \n",
       "\n",
       "      ADD_SUGARS  A_DRINKS  \n",
       "4939         0.0       0.0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_meal = df.sample(n=1, random_state=1)\n",
    "random_meal[food_cmp_level5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The component values for the randomly selected meal are displayed above. We can plug these in to the logistic probability equation from above, and can derive the probability of the meal containing seafood using the fitted model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of this meal containing seafood is:  0.8924882523661772\n"
     ]
    }
   ],
   "source": [
    "from math import exp \n",
    "X = np.array(random_meal[food_cmp_level5])\n",
    "Beta = np.array(log_reg_coefficients).T\n",
    "X_Beta = np.dot(X, Beta)\n",
    "b0 = log_reg_intercept\n",
    "p = (exp(b0 + X_Beta))/(1+exp(b0 + X_Beta))\n",
    "print(\"The probability of this meal containing seafood is: \", p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this initial point, we can then calculate how this probability changes if we change one component value while leaving the others constant. For example, we can try to decrease the F_JUICE component by 2, to 1.6 from 3.6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new X vector is:  [[0.   0.   1.6  0.03 0.2  0.   0.   0.   0.49 0.   0.   2.76 0.   0.\n",
      "  0.   0.   0.   0.   0.   1.96 0.09 0.   0.  ]]\n",
      "\n",
      "The probability of this meal containing seafood is:  0.7424340046290475\n"
     ]
    }
   ],
   "source": [
    "X[0,2] = 1.6\n",
    "print(\"The new X vector is: \", X)\n",
    "X_Beta = np.dot(X, Beta)\n",
    "b0 = log_reg_intercept\n",
    "p = (exp(b0 + X_Beta))/(1+exp(b0 + X_Beta))\n",
    "print(\"\\nThe probability of this meal containing seafood is: \", p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As was stated above, we can see in which direction the probability will change based on the sign for the component parameter. However, the actual change in probability depends on the values of the other parameters. This is due to the non-linear nature of the exponential function that the logistic regression uses to derive probabilities. Finally, did the model predict this meal correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4939    shrimp\n",
       "Name: species, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_meal['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This meal did indeed contain shrimp, so the model was able to classify this meal correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Diagnostics**\n",
    "\n",
    "The logistic regression success rate is a bit low, at around a 0.66 prediction success rate. So this model does not seem to be very representative of the real world behavior of food consumers. This may very well be due to the statistical distribution characteristics of the FPED components, which was explored in other reports. But we also know that regression models can be negatively affected by a dataset with a high number of variables, which is the case for this NHANES observations space. The model above was fitted using 23 variables, and the model solution will have a high variance if there is correlation within those components. Below is the correlation matrix for these components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "def histogram_intersection(a, b):\n",
    "    v = np.minimum(a, b).sum().round(decimals=1)\n",
    "    return v\n",
    "df = df[food_cmp_level5]\n",
    "corr = df.corr()\n",
    "#plot(corr.style.background_gradient(cmap='coolwarm'))\n",
    "plt.matshow(corr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation matrix does not show any high correlations among the components. The correlation values are actually quite low. Just as an extra cautionary step, the section below attempts to use a PCA transformation of the observation space and use the principal components to re-fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57740584 0.32557929 0.0784561  0.01022015 0.00256172]\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.652525\n",
      "std      0.024370\n",
      "min      0.580000\n",
      "25%      0.637500\n",
      "50%      0.647500\n",
      "75%      0.668125\n",
      "max      0.715000\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.654188\n",
      "std      0.010398\n",
      "min      0.625000\n",
      "25%      0.647344\n",
      "50%      0.653438\n",
      "75%      0.662500\n",
      "max      0.675625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>seafood_meal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.924300e+04</td>\n",
       "      <td>2.924300e+04</td>\n",
       "      <td>2.924300e+04</td>\n",
       "      <td>2.924300e+04</td>\n",
       "      <td>2.924300e+04</td>\n",
       "      <td>29243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.798703e-15</td>\n",
       "      <td>6.536280e-15</td>\n",
       "      <td>-4.624569e-17</td>\n",
       "      <td>1.979138e-16</td>\n",
       "      <td>7.060715e-17</td>\n",
       "      <td>0.110522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.496078e+01</td>\n",
       "      <td>1.123420e+01</td>\n",
       "      <td>5.514767e+00</td>\n",
       "      <td>1.990409e+00</td>\n",
       "      <td>9.965044e-01</td>\n",
       "      <td>0.313545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.424377e+01</td>\n",
       "      <td>-3.693371e+01</td>\n",
       "      <td>-2.491005e+01</td>\n",
       "      <td>-1.378501e+01</td>\n",
       "      <td>-1.841469e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.039567e+01</td>\n",
       "      <td>-6.831654e+00</td>\n",
       "      <td>-2.858451e+00</td>\n",
       "      <td>-1.133901e+00</td>\n",
       "      <td>-3.043622e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.324786e+00</td>\n",
       "      <td>-3.456396e+00</td>\n",
       "      <td>-1.725188e+00</td>\n",
       "      <td>-2.619344e-01</td>\n",
       "      <td>-2.329680e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.569037e+00</td>\n",
       "      <td>3.391805e+00</td>\n",
       "      <td>1.736275e+00</td>\n",
       "      <td>8.096234e-01</td>\n",
       "      <td>-1.748552e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.774602e+02</td>\n",
       "      <td>2.593593e+02</td>\n",
       "      <td>1.076395e+02</td>\n",
       "      <td>1.830589e+01</td>\n",
       "      <td>1.659055e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  2.924300e+04  2.924300e+04  2.924300e+04  2.924300e+04  2.924300e+04   \n",
       "mean   1.798703e-15  6.536280e-15 -4.624569e-17  1.979138e-16  7.060715e-17   \n",
       "std    1.496078e+01  1.123420e+01  5.514767e+00  1.990409e+00  9.965044e-01   \n",
       "min   -1.424377e+01 -3.693371e+01 -2.491005e+01 -1.378501e+01 -1.841469e+00   \n",
       "25%   -1.039567e+01 -6.831654e+00 -2.858451e+00 -1.133901e+00 -3.043622e-01   \n",
       "50%   -4.324786e+00 -3.456396e+00 -1.725188e+00 -2.619344e-01 -2.329680e-01   \n",
       "75%    5.569037e+00  3.391805e+00  1.736275e+00  8.096234e-01 -1.748552e-01   \n",
       "max    1.774602e+02  2.593593e+02  1.076395e+02  1.830589e+01  1.659055e+01   \n",
       "\n",
       "       seafood_meal  \n",
       "count  29243.000000  \n",
       "mean       0.110522  \n",
       "std        0.313545  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "\n",
    "X = df[food_cmp_level5]\n",
    "pca = PCA(n_components=5)\n",
    "pca_x = pca.fit(X)\n",
    "df_pca = pca_x.transform(X)\n",
    "df_new = pd.DataFrame(df_pca)\n",
    "\n",
    "\n",
    "df_new['seafood_meal'] = df['seafood_meal']\n",
    "\n",
    "var_sel = [0,1,2,3,4]\n",
    "\n",
    "\n",
    "print(pca_x.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_pred_sr_tot=[]\n",
    "train_pred_sr_tot=[]\n",
    "for i in range(100):\n",
    "    test_pred_sr, train_pred_sr = nhanes_full_log_reg(df = df_new,\n",
    "                                   fped_vars = var_sel, \n",
    "                                   non_sfd_class_n = 1000, \n",
    "                                   sfd_class_n = 1000, \n",
    "                                   test_ratio = 0.2)\n",
    "    test_pred_sr_tot.append(test_pred_sr)\n",
    "    train_pred_sr_tot.append(train_pred_sr)\n",
    "\n",
    "\n",
    "test_pred_sr_tot = pd.DataFrame(test_pred_sr_tot)\n",
    "test_pred_sr_tot = test_pred_sr_tot.astype(float)\n",
    "train_pred_sr_tot = pd.DataFrame(train_pred_sr_tot)\n",
    "train_pred_sr_tot = train_pred_sr_tot.astype(float)\n",
    "print(test_pred_sr_tot.describe())\n",
    "print(train_pred_sr_tot.describe())\n",
    "\n",
    "df_new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model above is fitted 100 different times, to account for the variances in the sampling of the data. The results above are showing the success rate distribution of these 100 runs. Five principal components, which explain most of the variation within the data, were used to re-fit the model. This model is actually performing worse than the original, re-iterating that correlation within the components is not an issue for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 2: Component-Wise Linear Regression**\n",
    "\n",
    "This section explores a linear regression model, targetting each one of the components while using the others. In this manner we can see how changing the amount of seafood on a plate will affect each of the components. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Regression Target       R^2       RMSE  Target Mean  Target SD\n",
      "24        SOLID_FATS  0.488401  10.013990     10.55589  14.007465\n",
      "22          D_CHEESE  0.468449   0.437460      0.21444   0.600320\n",
      "23              OILS  0.325445   9.751514      9.85552  11.879022\n",
      "10         G_REFINED  0.323397   1.823277      2.09176   2.217700\n",
      "19      PF_SEAFD_TOT  0.288836   2.525525      1.83201   2.996290\n",
      "18           PF_MEAT  0.208648   1.481895      0.70173   1.666671\n",
      "6   V_STARCHY_POTATO  0.192106   0.321119      0.14430   0.357443\n",
      "4     V_REDOR_TOMATO  0.171867   0.256515      0.14051   0.282021\n",
      "13         PF_NUTSDS  0.154644   0.391540      0.05461   0.426062\n",
      "17          PF_POULT  0.153676   1.587469      0.68087   1.726451\n",
      "25        ADD_SUGARS  0.153480   5.298738      3.61063   5.761971\n",
      "8            V_OTHER  0.141773   0.462492      0.33273   0.499483\n",
      "15      PF_CUREDMEAT  0.139455   0.816721      0.28877   0.880855\n",
      "11           PF_EGGS  0.116634   0.288373      0.10681   0.306974\n",
      "9            G_WHOLE  0.076042   0.546682      0.18344   0.569018\n",
      "20            D_MILK  0.071919   0.401900      0.14483   0.417390\n",
      "5      V_REDOR_OTHER  0.071725   0.134720      0.04519   0.139898\n",
      "3            V_DRKGR  0.053090   0.285205      0.09484   0.293238\n",
      "14        PF_LEGUMES  0.048688   0.815307      0.20966   0.836328\n",
      "26          A_DRINKS  0.038677   0.561471      0.12194   0.572941\n",
      "7    V_STARCHY_OTHER  0.037122   0.224318      0.06454   0.228715\n",
      "1            F_OTHER  0.034316   0.316904      0.07205   0.322647\n",
      "12            PF_SOY  0.019993   0.162955      0.01793   0.164691\n",
      "0           F_CITMLB  0.018741   0.240987      0.04065   0.243400\n",
      "2            F_JUICE  0.015150   0.378592      0.07032   0.381684\n",
      "16          PF_ORGAN  0.013154   0.233679      0.01647   0.235349\n",
      "21          D_YOGURT  0.010256   0.038004      0.00292   0.038220\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "def linear_regressor(df, obs_space, target, n_sfd, n_non_sfd):\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=n_non_sfd)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=n_sfd)\n",
    "    df = pd.concat([df_non_sfd, df_sfd])\n",
    "    df_x = df[obs_space]\n",
    "    df_y = df[target]\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(df_x, df_y)\n",
    "    y_pred = lin_reg.predict(df_x)\n",
    "    lin_mse = mean_squared_error(df_y, y_pred)\n",
    "    lin_mse = np.sqrt(lin_mse)\n",
    "    lin_r2 = r2_score(df_y, y_pred)\n",
    "    return target, lin_r2, lin_mse, df[target].describe()['mean'], df[target].describe()['std']\n",
    "\n",
    "\n",
    "food_cmp_level6 = ['F_CITMLB', 'F_OTHER', 'F_JUICE', \n",
    "                   'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', \n",
    "                   'V_STARCHY_OTHER', 'V_OTHER', \n",
    "                   'G_WHOLE','G_REFINED', \n",
    "                   'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', \n",
    "                   'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT', 'PF_MEAT', 'PF_SEAFD_TOT',\n",
    "                   'D_MILK', 'D_YOGURT', 'D_CHEESE', \n",
    "                   'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']  \n",
    "\n",
    "#Read the pre-processed dataframe.\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "\n",
    "result = []\n",
    "for var in food_cmp_level6:\n",
    "    obs_space = list(food_cmp_level6)\n",
    "    obs_space.remove(var)\n",
    "    #print(variables)\n",
    "    target = var\n",
    "    result_temp = linear_regressor(df, obs_space, var, 500, 500)\n",
    "    result.append(result_temp)\n",
    "    \n",
    "result = pd.DataFrame(result)\n",
    "result = result.rename(columns={0: \"Regression Target\", 1: \"R^2\", 2: \"RMSE\", 3: \"Target Mean\", 4:\"Target SD\"})\n",
    "result = result.sort_values(by=\"R^2\", ascending = False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above is showing the results of the linear regression model, targeting each component. The performance metric is the the standard model Root Mean Square Error, or RMSE. Given that each component has different units and distribution characteristics, the regression target component statistics are disaplyed above. The table is sorted by the R-squared result of the model. This provides an indication of how well the model predicts the quantities of the target component. As we can see, the better performing models are when regressing on SOLID_FATS and D_CHEESE. However, even for these models, the R-squared result is not very high.\n",
    "\n",
    "**Model Interpretation**\n",
    "\n",
    "The linear regression model is represented by the following equation:\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\beta_1X_1 + ... + \\beta_pX_p$$\n",
    "\n",
    "The interpretation here is that changing the value of a component by some unit, while holding all the other parameters constant, will change the prediction value by:\n",
    "\n",
    "$$\\delta\\hat{y} = \\beta_n \\delta X_n$$\n",
    "\n",
    "Since the linear regression on solid fats performed the best, we can use this as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The linear regression predictor variables are: \n",
      " ['F_CITMLB', 'F_OTHER', 'F_JUICE', 'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', 'V_STARCHY_OTHER', 'V_OTHER', 'G_WHOLE', 'G_REFINED', 'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', 'PF_CUREDMEAT', 'PF_ORGAN', 'PF_POULT', 'PF_MEAT', 'PF_SEAFD_TOT', 'D_MILK', 'D_YOGURT', 'D_CHEESE', 'OILS', 'ADD_SUGARS', 'A_DRINKS']\n",
      "\n",
      "\n",
      "The linear regression coefficients on SOLID_FATS are: \n",
      " [ 9.36136806e-05 -3.07388895e-04  5.23706205e-04  5.68146634e-05\n",
      "  1.42595451e-04 -5.59135261e-04  6.08344288e-05 -2.41502561e-04\n",
      " -2.14181140e-04  1.63839757e-05  9.71694764e-05 -6.33311412e-04\n",
      "  3.22683943e-04  1.83353777e-04  2.48870266e-01 -5.36502668e-05\n",
      " -1.32913699e-05  5.42045282e-05  9.21734886e-06 -2.70821736e-06\n",
      "  2.38046579e-04  1.12222444e-03 -1.67284936e-04  1.71555880e-06\n",
      " -1.61058470e-05  1.46566527e-04]\n",
      "\n",
      "\n",
      "The linear regression intercept on SOLID_FATS is: \n",
      " -9.028702816244599e-05\n",
      "\n",
      "\n",
      "The linear regression coefficient for PF_SEAFD_TOT is: \n",
      " -2.7082173596260176e-06\n",
      "\n",
      "\n",
      "So increasing the PF_SEAFD_TOT value by 1 unit, will change the amount of solid fats by:  -2.7082173596260176e-06\n",
      "\n",
      "\n",
      "And decreasing the PF_SEAFD_TOT value by 1 unit, will change the amount of solid fats by  2.7082173596260176e-06\n"
     ]
    }
   ],
   "source": [
    "def linear_regressor_params(df, obs_space, target, n_sfd, n_non_sfd):\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=n_non_sfd)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=n_sfd)\n",
    "    df = pd.concat([df_non_sfd, df_sfd])\n",
    "    df_x = df[obs_space]\n",
    "    df_y = df[target]\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(df_x, df_y)\n",
    "    y_pred = lin_reg.predict(df_x)\n",
    "    lin_mse = mean_squared_error(df_y, y_pred)\n",
    "    lin_mse = np.sqrt(lin_mse)\n",
    "    return lin_reg.coef_, lin_reg.intercept_\n",
    "\n",
    "\n",
    "obs_space = list(food_cmp_level6)\n",
    "obs_space.remove('SOLID_FATS')\n",
    "lin_reg_coefficients, lin_reg_intercept = linear_regressor_params(df, obs_space, 'V_LEGUMES', 500, 500)\n",
    "\n",
    "print(\"The linear regression predictor variables are: \\n\", obs_space)\n",
    "print(\"\\n\")\n",
    "print(\"The linear regression coefficients on SOLID_FATS are: \\n\", lin_reg_coefficients)\n",
    "print(\"\\n\")\n",
    "print(\"The linear regression intercept on SOLID_FATS is: \\n\", lin_reg_intercept)\n",
    "print(\"\\n\")\n",
    "print(\"The linear regression coefficient for PF_SEAFD_TOT is: \\n\", lin_reg_coefficients[19])\n",
    "print(\"\\n\")\n",
    "print(\"So increasing the PF_SEAFD_TOT value by 1 unit, will change the amount of solid fats by: \", lin_reg_coefficients[19])\n",
    "print(\"\\n\")\n",
    "print(\"And decreasing the PF_SEAFD_TOT value by 1 unit, will change the amount of solid fats by \", -lin_reg_coefficients[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even in this model, the coefficient for PF_SEAFD_TOT is too small to be used reliably for making inferences on how solid fats are consumed among seafood and non seafood meals. In addition to this, the poor performance on the linear regression when targeting the other components, indicates that a linear regression does not best represent the behavior in the real world. This model is most likely experiencing similar issues as the logistic regression model, where the distribution characterisitcs of the input data are not suited for regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Section 3: Decision Tree Model**\n",
    "\n",
    "Decision trees are an alternative to the regression approach, while still providing a certain level of explainability of the data features. Given the statistical characteristics of the features in this dataset, a decision tree may provide a more suitable model of the real world behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count  100.000000\n",
      "mean     0.588875\n",
      "std      0.025777\n",
      "min      0.520000\n",
      "25%      0.570000\n",
      "50%      0.587500\n",
      "75%      0.607500\n",
      "max      0.647500\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.998569\n",
      "std      0.000946\n",
      "min      0.996250\n",
      "25%      0.998125\n",
      "50%      0.998750\n",
      "75%      0.999375\n",
      "max      1.000000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "def tree_regressor(df, components, n_sfd, n_non_sfd):\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=n_non_sfd)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=n_sfd)\n",
    "    df = pd.concat([df_non_sfd, df_sfd])\n",
    "    df_x = df[components]\n",
    "    df_y = df['seafood_meal']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.2)\n",
    "    decision_tree = DecisionTreeClassifier()\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    y_pred_tree = decision_tree.predict(X_test)\n",
    "    y_pred_tree_train = decision_tree.predict(X_train)\n",
    "    #score = decision_tree.score(X_test, y_test)\n",
    "    score = accuracy_score(y_test, y_pred_tree)\n",
    "    score_train = accuracy_score(y_train, y_pred_tree_train)\n",
    "    tree_rules = export_text(decision_tree, feature_names=list(X_train.columns))\n",
    "    return score, score_train, tree_rules\n",
    "\n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "\n",
    "food_cmp_level5 = ['F_CITMLB', 'F_OTHER', 'F_JUICE', \n",
    "                   'V_DRKGR', 'V_REDOR_TOMATO', 'V_REDOR_OTHER', 'V_STARCHY_POTATO', \n",
    "                   'V_STARCHY_OTHER', 'V_OTHER', 'V_LEGUMES', \n",
    "                   'G_WHOLE','G_REFINED', \n",
    "                   'PF_EGGS', 'PF_SOY', 'PF_NUTSDS', 'PF_LEGUMES', \n",
    "                   'D_MILK', 'D_YOGURT', 'D_CHEESE', \n",
    "                   'OILS', 'SOLID_FATS', 'ADD_SUGARS', 'A_DRINKS']  \n",
    "\n",
    "var_sel = [0,1,2,3,4]\n",
    "\n",
    "result = []\n",
    "result_train = []\n",
    "for i in range(100):\n",
    "    model_fit, train_results, tree_rules = tree_regressor(df_new, var_sel, 1000, 1000)\n",
    "    result.append(model_fit)\n",
    "    result_train.append(train_results)\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "print(result.describe())\n",
    "\n",
    "result_train = pd.DataFrame(result_train)\n",
    "print(result_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction success rate is not much higher for this model. \n",
    "\n",
    "**Model Interpretation**\n",
    "\n",
    "The resulting decision tree is depicted below. The tree contains a high amount of branches, due to the high amount of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- 0 <= -7.10\n",
      "|   |--- 1 <= -3.08\n",
      "|   |   |--- 0 <= -12.49\n",
      "|   |   |   |--- 3 <= 2.82\n",
      "|   |   |   |   |--- 4 <= -0.24\n",
      "|   |   |   |   |   |--- 1 <= -6.56\n",
      "|   |   |   |   |   |   |--- 2 <= -1.07\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 2 >  -1.07\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 1 >  -6.56\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 4 >  -0.24\n",
      "|   |   |   |   |   |--- 0 <= -12.91\n",
      "|   |   |   |   |   |   |--- 0 <= -13.86\n",
      "|   |   |   |   |   |   |   |--- 3 <= -0.88\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -6.86\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -6.86\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  -0.88\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -1.63\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -1.63\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -6.80\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= -6.84\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  -6.84\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -6.80\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -1.53\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |--- 0 >  -13.86\n",
      "|   |   |   |   |   |   |   |--- 0 <= -13.79\n",
      "|   |   |   |   |   |   |   |   |--- 3 <= 0.18\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -0.98\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -0.98\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 3 >  0.18\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 0 >  -13.79\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -3.29\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= -1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= 0.23\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  0.23\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  -1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -1.74\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -1.74\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -3.29\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 0 >  -12.91\n",
      "|   |   |   |   |   |   |--- 2 <= 8.04\n",
      "|   |   |   |   |   |   |   |--- 1 <= -6.74\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -6.92\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -6.92\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  -6.74\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 2 >  8.04\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- 3 >  2.82\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- 0 >  -12.49\n",
      "|   |   |   |--- 2 <= -1.78\n",
      "|   |   |   |   |--- 1 <= -7.59\n",
      "|   |   |   |   |   |--- 2 <= -2.11\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 2 >  -2.11\n",
      "|   |   |   |   |   |   |--- 1 <= -7.76\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  -7.76\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 1 >  -7.59\n",
      "|   |   |   |   |   |--- 3 <= 0.07\n",
      "|   |   |   |   |   |   |--- 2 <= -1.81\n",
      "|   |   |   |   |   |   |   |--- 2 <= -2.07\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -2.44\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -2.44\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= -2.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  -2.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -2.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -2.12\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 2 >  -2.07\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -1.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -1.26\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= -11.98\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  -11.98\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.14\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 2 >  -1.81\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 3 >  0.07\n",
      "|   |   |   |   |   |   |--- 2 <= -2.05\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 2 >  -2.05\n",
      "|   |   |   |   |   |   |   |--- 2 <= -1.96\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -6.88\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -2.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -2.01\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -6.88\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -1.96\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 2 >  -1.78\n",
      "|   |   |   |   |--- 3 <= -1.37\n",
      "|   |   |   |   |   |--- 1 <= -7.22\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 1 >  -7.22\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 3 >  -1.37\n",
      "|   |   |   |   |   |--- 4 <= -0.18\n",
      "|   |   |   |   |   |   |--- 1 <= -5.73\n",
      "|   |   |   |   |   |   |   |--- 1 <= -7.45\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  -7.45\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= -10.42\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.20\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -1.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -1.64\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.20\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  -10.42\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= 5.04\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  5.04\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= -9.36\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  -9.36\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  -5.73\n",
      "|   |   |   |   |   |   |   |--- 1 <= -4.90\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  -4.90\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -1.52\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -1.52\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -11.91\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -11.91\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= -3.10\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  -3.10\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 4 >  -0.18\n",
      "|   |   |   |   |   |   |--- 4 <= 2.81\n",
      "|   |   |   |   |   |   |   |--- 1 <= -4.92\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= 5.93\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  5.93\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.16\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  -4.92\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -4.12\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -4.12\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 4 >  2.81\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |--- 1 >  -3.08\n",
      "|   |   |--- 0 <= -9.90\n",
      "|   |   |   |--- 3 <= -0.34\n",
      "|   |   |   |   |--- 4 <= 3.46\n",
      "|   |   |   |   |   |--- 1 <= 10.53\n",
      "|   |   |   |   |   |   |--- 4 <= -0.24\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 4 >  -0.24\n",
      "|   |   |   |   |   |   |   |--- 1 <= 2.66\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -2.34\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -1.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.17\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.17\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -1.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -2.34\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= 2.58\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= -0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  -0.56\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  2.58\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  2.66\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -2.91\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= -3.01\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  -3.01\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -2.91\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 1 >  10.53\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 4 >  3.46\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- 3 >  -0.34\n",
      "|   |   |   |   |--- 3 <= -0.12\n",
      "|   |   |   |   |   |--- 2 <= 0.31\n",
      "|   |   |   |   |   |   |--- 1 <= 9.61\n",
      "|   |   |   |   |   |   |   |--- 0 <= -10.47\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 0 >  -10.47\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= -10.29\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  -10.29\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  9.61\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 2 >  0.31\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 3 >  -0.12\n",
      "|   |   |   |   |   |--- 2 <= 0.58\n",
      "|   |   |   |   |   |   |--- 1 <= 2.73\n",
      "|   |   |   |   |   |   |   |--- 0 <= -13.23\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 0 >  -13.23\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= 0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -13.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= -13.17\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  -13.17\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -13.11\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= -11.76\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 7\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  -11.76\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  2.73\n",
      "|   |   |   |   |   |   |   |--- 3 <= 1.22\n",
      "|   |   |   |   |   |   |   |   |--- 3 <= 1.20\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -12.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -12.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= -0.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  -0.09\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |--- 3 >  1.20\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  1.22\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 2 >  0.58\n",
      "|   |   |   |   |   |   |--- 4 <= -0.34\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 4 >  -0.34\n",
      "|   |   |   |   |   |   |   |--- 2 <= 1.56\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  1.56\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.29\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.29\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= 0.20\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  0.20\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.27\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.27\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- 0 >  -9.90\n",
      "|   |   |   |--- 1 <= 4.85\n",
      "|   |   |   |   |--- 1 <= -2.89\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 1 >  -2.89\n",
      "|   |   |   |   |   |--- 0 <= -8.13\n",
      "|   |   |   |   |   |   |--- 0 <= -8.85\n",
      "|   |   |   |   |   |   |   |--- 2 <= -2.53\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 2 >  -2.53\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= -9.70\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  -9.70\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -9.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -9.66\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= -0.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  -0.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |--- 0 >  -8.85\n",
      "|   |   |   |   |   |   |   |--- 4 <= 0.48\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= -8.32\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  -8.32\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -8.28\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -8.28\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 4 >  0.48\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 0 >  -8.13\n",
      "|   |   |   |   |   |   |--- 1 <= 2.38\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 1 >  2.38\n",
      "|   |   |   |   |   |   |   |--- 1 <= 4.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 1 >  4.19\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 1 >  4.85\n",
      "|   |   |   |   |--- 2 <= -3.73\n",
      "|   |   |   |   |   |--- 1 <= 20.73\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 1 >  20.73\n",
      "|   |   |   |   |   |   |--- 3 <= -0.90\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 3 >  -0.90\n",
      "|   |   |   |   |   |   |   |--- 2 <= -4.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 2 >  -4.80\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 2 >  -3.73\n",
      "|   |   |   |   |   |--- 2 <= 8.25\n",
      "|   |   |   |   |   |   |--- 3 <= 1.90\n",
      "|   |   |   |   |   |   |   |--- 2 <= -1.72\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= 3.95\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  3.95\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -8.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -8.63\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -1.72\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -1.20\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -1.20\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.30\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 3 >  1.90\n",
      "|   |   |   |   |   |   |   |--- 0 <= -8.04\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 0 >  -8.04\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 2 >  8.25\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|--- 0 >  -7.10\n",
      "|   |--- 1 <= 12.04\n",
      "|   |   |--- 3 <= 1.40\n",
      "|   |   |   |--- 1 <= -5.99\n",
      "|   |   |   |   |--- 2 <= -4.24\n",
      "|   |   |   |   |   |--- 1 <= -11.17\n",
      "|   |   |   |   |   |   |--- 4 <= -0.31\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 4 >  -0.31\n",
      "|   |   |   |   |   |   |   |--- 4 <= -0.02\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.18\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.18\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -2.35\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= 57.83\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  57.83\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -2.35\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 4 >  -0.02\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 1 >  -11.17\n",
      "|   |   |   |   |   |   |--- 3 <= -0.14\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 3 >  -0.14\n",
      "|   |   |   |   |   |   |   |--- 0 <= 12.62\n",
      "|   |   |   |   |   |   |   |   |--- 3 <= 0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 3 >  0.27\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 0 >  12.62\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 2 >  -4.24\n",
      "|   |   |   |   |   |--- 3 <= 1.35\n",
      "|   |   |   |   |   |   |--- 1 <= -8.23\n",
      "|   |   |   |   |   |   |   |--- 2 <= -2.57\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -8.70\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= -3.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -3.26\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -3.26\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  -3.24\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -8.70\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -8.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -8.36\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -2.57\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= 2.91\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= 0.44\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= -8.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  -8.34\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  0.44\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  2.91\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= 1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  1.41\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  -8.23\n",
      "|   |   |   |   |   |   |   |--- 0 <= 25.55\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -2.89\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -1.86\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -1.86\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.15\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.15\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -2.89\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.17\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 9\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.18\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.17\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 0 >  25.55\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 3 >  1.35\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 1 >  -5.99\n",
      "|   |   |   |   |--- 0 <= 3.09\n",
      "|   |   |   |   |   |--- 0 <= 2.67\n",
      "|   |   |   |   |   |   |--- 2 <= -3.66\n",
      "|   |   |   |   |   |   |   |--- 2 <= -4.12\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -4.12\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= 2.08\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -1.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -1.82\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -3.75\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -3.75\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  2.08\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -0.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -0.34\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 2 >  -3.66\n",
      "|   |   |   |   |   |   |   |--- 3 <= -1.07\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= 3.51\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -5.87\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -5.87\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= -1.70\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  -1.70\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 4\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  3.51\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= -1.40\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  -1.40\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= 4.36\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  4.36\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  -1.07\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= 2.55\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= 1.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= 1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 12\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  1.78\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  1.95\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  2.55\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 <= 0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.27\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 6\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.27\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- 3 >  0.46\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 0 >  2.67\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 0 >  3.09\n",
      "|   |   |   |   |   |--- 0 <= 7.83\n",
      "|   |   |   |   |   |   |--- 1 <= -5.22\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 1 >  -5.22\n",
      "|   |   |   |   |   |   |   |--- 4 <= -0.30\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.33\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.33\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 4 >  -0.30\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= -3.56\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -3.75\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -3.75\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  -3.56\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 0 >  7.83\n",
      "|   |   |   |   |   |   |--- 0 <= 10.03\n",
      "|   |   |   |   |   |   |   |--- 4 <= -0.28\n",
      "|   |   |   |   |   |   |   |   |--- 1 <= 7.05\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 <= 10.68\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 2 >  10.68\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 1 >  7.05\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 4 >  -0.28\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 0 >  10.03\n",
      "|   |   |   |   |   |   |   |--- 2 <= -4.50\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= 24.43\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -0.93\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= -2.47\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  -2.47\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -0.93\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  24.43\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= -2.98\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  -2.98\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -4.50\n",
      "|   |   |   |   |   |   |   |   |--- 3 <= -0.05\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= -1.39\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  -1.39\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.21\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= 1.68\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  1.68\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- 3 >  -0.05\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.31\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 <= -0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 4 >  -0.41\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.31\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- 3 >  1.40\n",
      "|   |   |   |--- 4 <= 4.15\n",
      "|   |   |   |   |--- 3 <= 10.02\n",
      "|   |   |   |   |   |--- 1 <= -7.76\n",
      "|   |   |   |   |   |   |--- 1 <= -14.84\n",
      "|   |   |   |   |   |   |   |--- 3 <= 4.63\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 3 >  4.63\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  -14.84\n",
      "|   |   |   |   |   |   |   |--- 3 <= 5.60\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  5.60\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= 43.94\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  43.94\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 1 >  -7.76\n",
      "|   |   |   |   |   |   |--- 1 <= -7.27\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 1 >  -7.27\n",
      "|   |   |   |   |   |   |   |--- 2 <= -6.13\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= 0.80\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  0.80\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -6.13\n",
      "|   |   |   |   |   |   |   |   |--- 3 <= 6.38\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= -1.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= -0.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  -0.81\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  -1.32\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 <= 9.58\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 5\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 1 >  9.58\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |--- 3 >  6.38\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= 25.37\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  25.37\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- 3 >  10.02\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 4 >  4.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- 1 >  12.04\n",
      "|   |   |--- 0 <= 5.07\n",
      "|   |   |   |--- 4 <= 4.47\n",
      "|   |   |   |   |--- 3 <= -2.77\n",
      "|   |   |   |   |   |--- 3 <= -3.26\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 3 >  -3.26\n",
      "|   |   |   |   |   |   |--- 0 <= -6.21\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 0 >  -6.21\n",
      "|   |   |   |   |   |   |   |--- 2 <= -3.09\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 2 >  -3.09\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.35\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.35\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 3 >  -2.77\n",
      "|   |   |   |   |   |--- 2 <= -1.12\n",
      "|   |   |   |   |   |   |--- 0 <= -6.68\n",
      "|   |   |   |   |   |   |   |--- 3 <= 1.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 3 >  1.05\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 0 >  -6.68\n",
      "|   |   |   |   |   |   |   |--- 3 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- 2 <= -6.86\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |--- 2 >  -6.86\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= 3.18\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= -2.71\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  -2.71\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 2\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  3.18\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 <= 1.35\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 3 >  1.35\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 3 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 2 >  -1.12\n",
      "|   |   |   |   |   |   |--- 1 <= 14.50\n",
      "|   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 1 >  14.50\n",
      "|   |   |   |   |   |   |   |--- 3 <= -1.04\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.31\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 <= 1.65\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 <= 3.07\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 2 >  3.07\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 0 >  1.65\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.31\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  -1.04\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.49\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 <= -0.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |   |--- 4 >  -0.60\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 <= -2.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |   |--- 0 >  -2.72\n",
      "|   |   |   |   |   |   |   |   |   |   |   |--- truncated branch of depth 3\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.49\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- 4 >  4.47\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |--- 0 >  5.07\n",
      "|   |   |   |--- 1 <= 55.94\n",
      "|   |   |   |   |--- 4 <= -0.48\n",
      "|   |   |   |   |   |--- 0 <= 63.62\n",
      "|   |   |   |   |   |   |--- 2 <= 7.82\n",
      "|   |   |   |   |   |   |   |--- 1 <= 25.93\n",
      "|   |   |   |   |   |   |   |   |--- 4 <= -0.75\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 4 >  -0.75\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 <= 24.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |   |   |--- 1 >  24.83\n",
      "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 1 >  25.93\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- 2 >  7.82\n",
      "|   |   |   |   |   |   |   |--- 4 <= -0.69\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 4 >  -0.69\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- 0 >  63.62\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- 4 >  -0.48\n",
      "|   |   |   |   |   |--- 2 <= 1.29\n",
      "|   |   |   |   |   |   |--- 1 <= 27.53\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 1 >  27.53\n",
      "|   |   |   |   |   |   |   |--- 3 <= -2.79\n",
      "|   |   |   |   |   |   |   |   |--- 0 <= 19.87\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |   |--- 0 >  19.87\n",
      "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  -2.79\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- 2 >  1.29\n",
      "|   |   |   |   |   |   |--- 0 <= 14.95\n",
      "|   |   |   |   |   |   |   |--- 3 <= 1.45\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- 3 >  1.45\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- 0 >  14.95\n",
      "|   |   |   |   |   |   |   |--- 0 <= 33.29\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- 0 >  33.29\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- 1 >  55.94\n",
      "|   |   |   |   |--- class: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine Model**\n",
    "\n",
    "A Support Vector Machine model does not provide any explainability of the model features, but is explored here to see if it can provide any improvement in performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count  100.000000\n",
      "mean     0.626700\n",
      "std      0.037025\n",
      "min      0.510000\n",
      "25%      0.600000\n",
      "50%      0.625000\n",
      "75%      0.655000\n",
      "max      0.715000\n",
      "                0\n",
      "count  100.000000\n",
      "mean     0.635637\n",
      "std      0.018919\n",
      "min      0.583750\n",
      "25%      0.621250\n",
      "50%      0.635625\n",
      "75%      0.651250\n",
      "max      0.673750\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "df = pd.read_csv('../../Data/nhanes_full_pre_proc.csv')\n",
    "df = df[df['meal_energy']=='Medium-Low']\n",
    "\n",
    "\n",
    "def svm_regressor(df, variables, n_sfd, n_non_sfd, param):\n",
    "\n",
    "    df_non_sfd = df[df['seafood_meal']==0].sample(n=n_non_sfd)\n",
    "    df_sfd = df[df['seafood_meal']==1].sample(n=n_sfd)\n",
    "    df = pd.concat([df_non_sfd, df_sfd])\n",
    "\n",
    "    X = df[variables]\n",
    "    Y = df['seafood_meal']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    \n",
    "    #svm_nhanes = LinearSVC(C=1, loss=\"hinge\")\n",
    "    \n",
    "    svm_nhanes = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=param, loss=\"hinge\"))\n",
    "    ])\n",
    "\n",
    "    #svm_nhanes = LinearSVC(C=1, loss=\"hinge\")\n",
    "    svm_nhanes.fit(X_train, y_train)\n",
    "    y_pred_svm = svm_nhanes.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred_svm)\n",
    "    y_pred_svm_train = svm_nhanes.predict(X_train)\n",
    "    score_train = accuracy_score(y_train, y_pred_svm_train)\n",
    "    return score, score_train\n",
    "\n",
    "var_sel = [0,1,2,3,4]  \n",
    "\n",
    "result = []\n",
    "result_train = []\n",
    "for i in range(100):\n",
    "    model_fit, train_result = svm_regressor(df_new, var_sel, 500, 500, 1)\n",
    "    result.append(model_fit)\n",
    "    result_train.append(train_result)\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "result_train = pd.DataFrame(result_train)\n",
    "print(result.describe())\n",
    "print(result_train.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model does not provide any improvement in performance from the previous models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
